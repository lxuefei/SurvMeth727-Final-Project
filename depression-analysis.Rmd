---
title: "dp-analysis"
output: html_document
---
```{r}
#install.packages("wordcloud2")
#install.packages("lubridate")
#install.packages("jiebaR")
#install.packages("jiebaRD")
#install.packages("vcd")
#install.packages("ggpubr")
#install.packages("rowr")
library(rtweet)
library(twitteR)
library(syuzhet)
library(tm)
library(SnowballC)
library(tidytext)
library(ggmap)
library(dplyr)
library(ggplot2)
library(lubridate)
library(wordcloud2)
library(jiebaR)
library(jiebaRD)
library(vcd)
library(ggpubr)
library(rowr)

```

```{r}
# import data to excel format
dp1 <- read.csv("dp1-date.csv")
dp2 <- read.csv("dp2-date.csv")
dp3 <- read.csv("dp3-date.csv")
```


```{r}
# Set date format
dp1$date <- as.Date(dp1$created_at)
dp2$date <- as.Date(dp2$created_at)
dp2$date <- as.Date(dp2$created_at)

# Set time format
dp1$time <- ymd_hms(dp1$created_at)
dp2$time <- ymd_hms(dp2$created_at)
dp3$time <- ymd_hms(dp3$created_at)
```

```{r}
# Create wordclouds for each group
dp1_text <- as.character(dp1$text)

seg <- qseg[dp1_text] #使用qseg类型分词
seg <- seg[nchar(seg)>1] #去除字符长度小于1的词
seg <- table(seg)
seg <- seg[!grepl('[0-9]+',names(seg))]#过滤数字

seg_50 <- sort(seg, decreasing = TRUE)[1:50]
#获得词频数前50的词
seg_50
barplot(seg_50)
wordcloud2(seg,size = 2, minRotation = -pi/2, maxRotation = -pi/2) # Create wordcloud
```

```{r}
# merge different group, add group as a variable
group_1 <- rep(1, times = nrow(dp1))
dp1$group <- group_1
group_2 <- rep(2, times = nrow(dp2))
dp2$group <- group_2
group_3 <- rep(3, times = nrow(dp3))
dp3$group <- group_3

dp_all <- bind_rows(dp1,dp2,dp3)
dp_all$group = factor(dp_all$group, levels = c(1,2,3), labels = c("group1", "group2", "group3"))
head(dp_all)

```

```{r}
# Descriptive statistics - 定量数据
summary(dp_all)

dp_agg <- dp_all %>%
  select(display_text_width, followers_count, friends_count, listed_count, statuses_count, favourites_count, group) 
dp_stats <- aggregate(dp_agg[,(1:6)], by = list(dp_agg$group), FUN = mean)
colnames(dp_stats)[1] <- "group"
dp_stats


# 定量数据图

p1 <- ggplot(data = dp_stats, aes(y = followers_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
p2 <- ggplot(data = dp_stats, aes(y = friends_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
p3 <- ggplot(data = dp_stats, aes(y = statuses_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
p4 <- ggplot(data = dp_stats, aes(y = favourites_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
ggarrange(p1,p2,p3,p4, ncol=2,nrow=2,labels=c("A","B","C","D"))
  

# Descriptive statistics - 分类数据
ggplot(dp_all) +
  geom_bar(mapping = aes(x = source)) +
  coord_flip()

```

```{r}
# 统计分析 - 比较三组的follower是否有区别
df_test <- cbind.fill(dp1$followers_count, dp2$followers_count, dp3$followers_count, fill = NA)
df_folw <- cbind.fill(dp_agg$group, dp_agg$followers_count)
colnames(df_folw) <- c("group", "folw_n")

# Shapiro-Wilk normality test for group1
with(df_folw, shapiro.test(folw_n[group == "group1"])) # p =
# Shapiro-Wilk normality test for group2
with(df_folw, shapiro.test(folw_n[group == "group2"])) # p =
# Shapiro-Wilk normality test for group3
with(df_folw, shapiro.test(folw_n[group == "group3"])) # p =
# From the output, the two p-values are greater than the significance level 0.05 implying that the distribution of the data are not significantly different from the normal distribution. In other words, we can assume the normality.

#if the data are not normally distributed, it’s recommended to use the non parametric two-samples Wilcoxon rank test.

#Group 1 vs. Group 2
#Assumption 3. Do the two populations have the same variances?
df_folw_12 <- df_folw %>%
  filter(group == "group1" | group == "group2")
res.ftest <- var.test(folw_n ~ group, data = df_folw_12)
res.ftest
#The p-value of F-test is p = 0.1713596. It’s greater than the significance level alpha = 0.05. In conclusion, there is no significant difference between the variances of the two sets of data. Therefore, we can use the classic t-test witch assume equality of the two variances.

#t-test
res_folw_12 <- t.test(folw_n ~ group, data = df_folw_12, var.equal = FALSE)
res_folw_12
```