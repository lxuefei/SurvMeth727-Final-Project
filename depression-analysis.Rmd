---
title: "dp-analysis"
output: html_document
---
```{r}
#install.packages("wordcloud2")
#install.packages("lubridate")
#install.packages("jiebaR")
#install.packages("jiebaRD")
#install.packages("vcd")
#install.packages("ggpubr")
#install.packages("rowr")
#install.packages("Rsentiment")
library(rtweet)
library(twitteR)
library(syuzhet)
library(tm)
library(SnowballC)
library(tidytext)
library(ggmap)
library(dplyr)
library(ggplot2)
library(lubridate)
library(wordcloud2)
library(jiebaR)
library(jiebaRD)
library(vcd)
library(ggpubr)
library(rowr)
library(readr)
library(stringr)
library(DT)

```

```{r}
# import data to excel format
dp1 <- read.csv("dp1-date.csv")
dp2 <- read.csv("dp2-date.csv")
dp3 <- read.csv("dp3-date.csv")
```


```{r}
# Set date format
dp1$date <- as.Date(dp1$created_at)
dp2$date <- as.Date(dp2$created_at)
dp2$date <- as.Date(dp2$created_at)

# Set time format
dp1$time <- ymd_hms(dp1$created_at)
dp2$time <- ymd_hms(dp2$created_at)
dp3$time <- ymd_hms(dp3$created_at)
```

```{r}
# Create wordclouds for each group
dp1_text <- as.character(dp1$text)

seg <- qseg[dp1_text] #使用qseg类型分词
seg <- seg[nchar(seg)>1] #去除字符长度小于1的词
seg

# Set stopwords
all_stops <- c("and","of","http","to","for","in","on","the","with","at","or","from")
seg <- removeWords(seg, all_stops)
seg <- table(seg)

seg_50 <- sort(seg, decreasing = TRUE)[1:50]
#获得词频数前50的词
seg_50
barplot(seg_50)
wordcloud2(seg,size = 2, minRotation = -pi/2, maxRotation = -pi/2) # Create wordcloud
```

```{r}
# merge different group, add group as a variable
group_1 <- rep(1, times = nrow(dp1))
dp1$group <- group_1
group_2 <- rep(2, times = nrow(dp2))
dp2$group <- group_2
group_3 <- rep(3, times = nrow(dp3))
dp3$group <- group_3

dp_all <- bind_rows(dp1,dp2,dp3)
dp_all$group = factor(dp_all$group, levels = c(1,2,3), labels = c("group1", "group2", "group3"))
head(dp_all)

```

```{r}
# Descriptive statistics - 定量数据
summary(dp_all)

dp_agg <- dp_all %>%
  select(display_text_width, followers_count, friends_count, listed_count, statuses_count, favourites_count, group) 
dp_stats <- aggregate(dp_agg[,(1:6)], by = list(dp_agg$group), FUN = mean)
colnames(dp_stats)[1] <- "group"
dp_stats


# 定量数据图

p1 <- ggplot(data = dp_stats, aes(y = followers_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
p2 <- ggplot(data = dp_stats, aes(y = friends_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
p3 <- ggplot(data = dp_stats, aes(y = statuses_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
p4 <- ggplot(data = dp_stats, aes(y = favourites_count, x = group, fill = group)) +
  geom_bar(stat="identity") +
  theme_minimal()
ggarrange(p1,p2,p3,p4, ncol=2,nrow=2,labels=c("A","B","C","D"))
  

# Descriptive statistics - 分类数据
dp_all %>%
  group_by(source) %>%
  summarise(total = n()) %>%
  filter(source == "Facebook"|source == "Instagram"|source == "Tweetbot for iOS"|source == "TweetDeck"|source == "twittbot.net"|source == "Twitter for Android"|source == "Twitter for iPad"|source == "Twitter for iPhone"|source == "Twitter Web App"|source == "Twitter Web Client") %>%
  ggplot() +
  geom_bar(mapping = aes(x = reorder(source, total), y = total), stat = 'identity', fill = 'skyblue2') +
  coord_flip()

```

```{r}
# Statistical Analysis - Comparison the Followers over three groups

# Prepare dataset
df_folw <- cbind.fill(dp_agg$group, dp_agg$followers_count)
colnames(df_folw) <- c("group", "folw_n")

# Shapiro-Wilk normality test for three groups
with(df_folw, shapiro.test(folw_n[group == "group1"])) 
with(df_folw, shapiro.test(folw_n[group == "group2"])) 
with(df_folw, shapiro.test(folw_n[group == "group3"])) 
# From the output, the two p-values are smaller than the significance level 0.05 implying that the distribution of the data are not significantly different from the normal distribution. In other words, we cannot assume the normality.

# Group 1 vs. Group 2
# Test whether the two populations have the same variances
df_folw_12 <- df_folw %>%
  filter(group == "group1" | group == "group2")
res.ftest <- var.test(folw_n ~ group, data = df_folw_12)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_folw_12 <- t.test(folw_n ~ group, data = df_folw_12, var.equal = FALSE)
res_folw_12

# Group 2 vs. Group 3
# Test whether the two populations have the same variances
df_folw_23 <- df_folw %>%
  filter(group == "group2" | group == "group3")
res.ftest <- var.test(folw_n ~ group, data = df_folw_23)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_folw_23 <- t.test(folw_n ~ group, data = df_folw_23, var.equal = FALSE)
res_folw_23

# Group 1 vs. Group 3
# Test whether the two populations have the same variances
df_folw_13 <- df_folw %>%
  filter(group == "group1" | group == "group3")
res.ftest <- var.test(folw_n ~ group, data = df_folw_13)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_folw_13 <- t.test(folw_n ~ group, data = df_folw_13, var.equal = FALSE)
res_folw_13
```

```{r}
# Statistical Analysis - Comparison the Friends over three groups

# Prepare dataset
df_frid <- cbind.fill(dp_agg$group, dp_agg$friends_count)
colnames(df_frid) <- c("group", "frid_n")

# Shapiro-Wilk normality test for three groups
with(df_frid, shapiro.test(frid_n[group == "group1"])) 
with(df_frid, shapiro.test(frid_n[group == "group2"])) 
with(df_frid, shapiro.test(frid_n[group == "group3"])) 
# From the output, the two p-values are smaller than the significance level 0.05 implying that the distribution of the data are not significantly different from the normal distribution. In other words, we cannot assume the normality.

# Group 1 vs. Group 2
# Test whether the two populations have the same variances
df_frid_12 <- df_frid %>%
  filter(group == "group1" | group == "group2")
res.ftest <- var.test(frid_n ~ group, data = df_frid_12)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_frid_12 <- t.test(frid_n ~ group, data = df_frid_12, var.equal = FALSE)
res_frid_12

# Group 2 vs. Group 3
# Test whether the two populations have the same variances
df_frid_23 <- df_frid %>%
  filter(group == "group2" | group == "group3")
res.ftest <- var.test(frid_n ~ group, data = df_frid_23)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_frid_23 <- t.test(frid_n ~ group, data = df_frid_23, var.equal = FALSE)
res_frid_23

# Group 1 vs. Group 3
# Test whether the two populations have the same variances
df_frid_13 <- df_frid %>%
  filter(group == "group1" | group == "group3")
res.ftest <- var.test(frid_n ~ group, data = df_frid_13)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_frid_13 <- t.test(frid_n ~ group, data = df_frid_13, var.equal = FALSE)
res_frid_13
```

```{r}
# Statistical Analysis - Comparison the Statuses over three groups

# Prepare dataset
df_stat <- cbind.fill(dp_agg$group, dp_agg$statuses_count)
colnames(df_stat) <- c("group", "stat_n")

# Shapiro-Wilk normality test for three groups
with(df_stat, shapiro.test(stat_n[group == "group1"])) 
with(df_stat, shapiro.test(stat_n[group == "group2"])) 
with(df_stat, shapiro.test(stat_n[group == "group3"])) 
# From the output, the two p-values are smaller than the significance level 0.05 implying that the distribution of the data are not significantly different from the normal distribution. In other words, we cannot assume the normality.

# Group 1 vs. Group 2
# Test whether the two populations have the same variances
df_stat_12 <- df_stat %>%
  filter(group == "group1" | group == "group2")
res.ftest <- var.test(stat_n ~ group, data = df_stat_12)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_stat_12 <- t.test(stat_n ~ group, data = df_stat_12, var.equal = FALSE)
res_stat_12

# Group 2 vs. Group 3
# Test whether the two populations have the same variances
df_stat_23 <- df_stat %>%
  filter(group == "group2" | group == "group3")
res.ftest <- var.test(stat_n ~ group, data = df_stat_23)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_stat_23 <- t.test(stat_n ~ group, data = df_stat_23, var.equal = FALSE)
res_stat_23

# Group 1 vs. Group 3
# Test whether the two populations have the same variances
df_stat_13 <- df_stat %>%
  filter(group == "group1" | group == "group3")
res.ftest <- var.test(stat_n ~ group, data = df_stat_13)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_stat_13 <- t.test(stat_n ~ group, data = df_stat_13, var.equal = FALSE)
res_stat_13
```

```{r}
# Statistical Analysis - Comparison the Favourites over three groups

# Prepare dataset
df_favr <- cbind.fill(dp_agg$group, dp_agg$favourites_count)
colnames(df_favr) <- c("group", "favr_n")

# Shapiro-Wilk normality test for three groups
with(df_favr, shapiro.test(favr_n[group == "group1"])) 
with(df_favr, shapiro.test(favr_n[group == "group2"])) 
with(df_favr, shapiro.test(favr_n[group == "group3"])) 
# From the output, the two p-values are smaller than the significance level 0.05 implying that the distribution of the data are not significantly different from the normal distribution. In other words, we cannot assume the normality.

# Group 1 vs. Group 2
# Test whether the two populations have the same variances
df_favr_12 <- df_favr %>%
  filter(group == "group1" | group == "group2")
res.ftest <- var.test(favr_n ~ group, data = df_favr_12)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_favr_12 <- t.test(favr_n ~ group, data = df_favr_12, var.equal = FALSE)
res_favr_12

# Group 2 vs. Group 3
# Test whether the two populations have the same variances
df_favr_23 <- df_favr %>%
  filter(group == "group2" | group == "group3")
res.ftest <- var.test(favr_n ~ group, data = df_favr_23)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_favr_23 <- t.test(favr_n ~ group, data = df_favr_23, var.equal = FALSE)
res_favr_23

# Group 1 vs. Group 3
# Test whether the two populations have the same variances
df_favr_13 <- df_favr %>%
  filter(group == "group1" | group == "group3")
res.ftest <- var.test(favr_n ~ group, data = df_favr_13)
res.ftest
#The p-value of F-test is p < 0.05. It’s smaller than the significance level alpha = 0.05. In conclusion, there is a significant difference between the variances of the two sets of data.

#t-test
res_favr_13 <- t.test(favr_n ~ group, data = df_favr_13, var.equal = FALSE)
res_favr_13
```

```{r}
# Time analysis

# Extract date to cover the NA
dp_all$date <- as.Date(dp_all$time)

# Create new time variables: roundhour, hour, roundmin, minute
ymd(19970316); myd(03199716); dmy(16031997)
test_date <- ymd_hms("1997-03-16 12:01:30")
dp_all$roundhour <- round_date(dp_all$time, 'hour')
dp_all$roundmin <- round_date(dp_all$time, "minute")
dp_all$hour <- hour(dp_all$roundhour)
dp_all$minute <- minute(dp_all$roundmin)

# Graph twitter counts in 24 hours
dp_all %>%
  group_by(group, hour) %>%
  summarise(total = n()) %>%
  ggplot() +
  geom_bar(mapping = aes(x = hour, y = total, fill = group), stat = "identity")+
  geom_line(mapping = aes(x = hour, y = total, fill = group), colour = "navy") +
  theme_minimal() 
# Focus on group 3
dp_all %>%
  group_by(group, hour) %>%
  summarise(total = n()) %>%
  filter(group == "group3") %>%
  ggplot() +
  geom_bar(mapping = aes(x = hour, y = total), stat = "identity", fill = "lightblue") +
  geom_line(mapping = aes(x = hour, y = total), colour = "navy") +
  theme_minimal()
```

```{r}
# Sentiment analysis

# Extract text
dp_all$twttext <- as.character(dp_all$text)

# Text cleaning
dp_all$twttext %<>%
  gsub("(RT|via)((?:\\b\\w*@\\w+)+)", " ", .) %>%
  gsub("http[^[:blank:]]+", " ", .) %>%
  gsub("@\\w+", " ", .) %>%
  gsub("[[:punct:]]", " ", .) %>%
  gsub("[^[:alnum:]]", " ", .)

sentiment <- get_nrc_sentiment(dp_all$twttext, language = 'english')

stm.positive <- sum(sentiment$positive)
stm.anger <- sum(sentiment$anger)
stm.anticipation <- sum(sentiment$anticipation)
stm.disgust <- sum(sentiment$disgust)
stm.fear <- sum(sentiment$fear)
stm.joy <- sum(sentiment$joy)
stm.sadness <- sum(sentiment$sadness)
stm.surprise <- sum(sentiment$surprise)
stm.trust <- sum(sentiment$trust)
stm.negative <- sum(sentiment$negative)

# Create sentiment data frame
sentiment_type <- c("Positive", "Anger", "Anticipation", "Disgust", "Fear", "Joy", "Sadness", "Surprise", "Trust", "Negative")
score <- c(stm.positive, stm.anger, stm.anticipation, stm.disgust, stm.fear, stm.joy, stm.sadness, stm.surprise, stm.trust, stm.negative)
sentiment_data <- data.frame(sentiment_type, score)

# Graph sentiment
yaxis <- c(stm.positive, stm.anger, stm.anticipation, stm.disgust, stm.fear, stm.joy, stm.sadness, stm.surprise, stm.trust, stm.negative)
xaxis <- c("Positive", "Anger", "Anticipation", "Disgust", "Fear", "Joy", "Sadness", "Surprise", "Trust", "Negative")
color <- c("palegreen4", "orangered4", "palegreen3", "orangered3", "orangered4", "palegreen4", "orangered3", "palegreen3", "palegreen4", "orangered4")
yrange <- range(0, yaxis)
barplot(yaxis, names.arg = xaxis, xlab = "Sentiment Categories", ylab = "Sentiment Score", main = "Twitter sentiment for 'Depression'", col = color, border = "white", ylim = yrange, cex.axis = 0.6, cex.names = 0.6)
stm_table <- c(stm.positive, stm.anger, stm.anticipation, stm.disgust, stm.fear, stm.joy, stm.sadness, stm.surprise, stm.trust, stm.negative)
```
